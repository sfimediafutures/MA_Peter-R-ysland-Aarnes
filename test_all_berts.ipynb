{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import conllu\n",
    "import tqdm\n",
    "import torch\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional\n",
    "from functools import partial\n",
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from get_parl_corpus_token_data import ParlamentaryCorpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Could tidy up this one to just use device instead of calling gpu=true etc.\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    gpu = False\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conllu stuff\n",
    "def filter_tags(x):\n",
    "    return x        \n",
    "\n",
    "def convert_to_list_dict(path, file):\n",
    "    path = path.format(file)\n",
    "    with open(path, encoding=\"UTF-8\") as infile:\n",
    "        lst = []\n",
    "        tokens = list(conllu.parse_incr(infile))\n",
    "        for sent in tokens:\n",
    "                dic = {\n",
    "                \"idx\": sent.metadata[\"sent_id\"],\n",
    "                \"text\": sent.metadata[\"text\"].lower(),\n",
    "                \"tokens\": [token[\"form\"].lower() for token in sent],\n",
    "                \"lemmas\": [token[\"lemma\"] for token in sent],\n",
    "                \"pos_tags\": [token[\"upos\"] for token in sent],\n",
    "                \"ner_tags\": [filter_tags(token[\"misc\"].get(\"name\", \"O\")) for token in sent],\n",
    "            }\n",
    "                lst.append(dic) \n",
    "        print(\"Converting {} to list of dictionaries\\n     {} elements converted..\".format(file, len(lst)))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ltgoslo/NorBERT/blob/main/benchmarking/experiments/dataset.py\n",
    "\n",
    "\n",
    "\n",
    "class CoNLLDataset(Dataset):\n",
    "    def __init__(self, x_tokens, y_labels, ner_vocab=None):\n",
    "        self.tokens = [[x for x in entry] for entry in x_tokens]\n",
    "        self.ner_labels = [[y for y in entry] for entry in y_labels]\n",
    "\n",
    "        # hard coded ner_vocab to avoid random shuffled instanciation of ordering of ner_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.ner_indexer = {i: n for n, i in enumerate(self.ner_vocab)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokens = self.tokens[index]\n",
    "        ner_labels = self.ner_labels[index]\n",
    "\n",
    "        x = tokens\n",
    "        y = torch.LongTensor([self.ner_indexer[i] if i in self.ner_vocab\n",
    "                              else self.ner_indexer['@UNK'] for i in ner_labels])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dynamic padding. Takes the longest sentence in batch and pads other sentences to its length (if im not mistaken)\"\"\"\n",
    "# Function borrowed from https://github.com/ltgoslo/NorBERT/blob/main/benchmarking/experiments/bert_ner.py\n",
    "\n",
    "def collate_fn(batch, gpu=False):\n",
    "    longest_y = max([y.size(0) for X, y in batch])\n",
    "    x = [X for X, y in batch]\n",
    "    y = torch.stack(\n",
    "        [functional.pad(y, (0, longest_y - y.size(0)), value=-1) for X, y in batch]) #https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html\n",
    "    if gpu:\n",
    "        y = y.to(\"cuda\")\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert(nn.Module):\n",
    "    def __init__(self, ner_vocab, model_path=None, freeze=False):\n",
    "        super().__init__()\n",
    "        self._bert = BertModel.from_pretrained(\n",
    "            model_path\n",
    "        )\n",
    "        hidden_size = self._bert.config.hidden_size\n",
    "        self._linear = nn.Linear(hidden_size, len(ner_vocab))\n",
    "\n",
    "        if freeze:\n",
    "            for param in self._bert.parameters():\n",
    "                param.requires_grad = False #Freezing bert layer\n",
    "\n",
    "    def forward(self, batch, mask):\n",
    "        b = self._bert(\n",
    "            input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "        pooler = b.last_hidden_state[:, mask].diagonal().permute(2, 0, 1) #https://pytorch.org/docs/stable/generated/torch.permute.html\n",
    "        return self._linear(pooler)                                     #https://pytorch.org/docs/stable/generated/torch.diagonal.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ltgoslo/NorBERT/blob/main/benchmarking/experiments/bert_ner.py \n",
    "\n",
    "def build_mask(tokenizer, ids):\n",
    "    tok_sents = [tokenizer.convert_ids_to_tokens(i) for i in ids]\n",
    "    mask = []\n",
    "    for sentence in tok_sents:\n",
    "        current = []\n",
    "        for n, token in enumerate(sentence):\n",
    "            if token in tokenizer.all_special_tokens[1:] or token.startswith(\"##\"): # ## masked\n",
    "                continue\n",
    "            else:\n",
    "                current.append(n)\n",
    "        mask.append(current)\n",
    "\n",
    "    mask = tokenizer.pad({\"input_ids\": mask}, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data, tokenizer, model, gpu=False):\n",
    "    input_data = tokenizer(\n",
    "        input_data, is_split_into_words=True, return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "    if gpu:\n",
    "        input_data = input_data.to(\"cuda\")\n",
    "    batch_mask = build_mask(tokenizer, input_data[\"input_ids\"])\n",
    "    y_pred = model(input_data, batch_mask).permute(0, 2, 1).argmax(dim=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(test_set, ner_vocab, tokenizer, model):\n",
    "    model.eval()\n",
    "    predicted_labels = []\n",
    "    test_set = tqdm.tqdm(test_set)\n",
    "    for x, y in test_set:\n",
    "        y_pred = predict(x, tokenizer, model, gpu=gpu)\n",
    "        predicted = [ner_vocab[element] for element in y_pred[0]]\n",
    "        predicted_labels += predicted\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_freeze(freeze, model):\n",
    "    if freeze:\n",
    "        lr=0.001\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        lr = 2e-5\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return optimiser, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parl_corpus(rootdir_parl_corpus, lower=False):\n",
    "    corpora_normal_cap, corpora_lower, paths = [], [], []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(rootdir_parl_corpus):\n",
    "        for file in files:\n",
    "            if \"normalized_token_data.json\" in file:\n",
    "                path = (os.path.join(subdir, file))\n",
    "                paths.append(path)\n",
    "\n",
    "    for corpus, path in enumerate(paths):\n",
    "        corpus = ParlamentaryCorpus(path)\n",
    "        corpus = corpus.load_data()\n",
    "        corpora_normal_cap.append(corpus)\n",
    "        for k, v in corpus.items():\n",
    "            if v == []:\n",
    "                print(k)\n",
    "                print(path)\n",
    "\n",
    "    if lower==True:\n",
    "        for corpus, path in enumerate(paths):\n",
    "            corpus = ParlamentaryCorpus(path)\n",
    "            corpus = corpus.load_data(lower=True)\n",
    "            corpora_lower.append(corpus)\n",
    "\n",
    "\n",
    "    return corpora_normal_cap, corpora_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parl_sentences_only(dictionary_corpus):\n",
    "    corp = []\n",
    "    for diction in dictionary_corpus:\n",
    "        corp += list(diction.values())\n",
    "    return corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Provides dummy y-data so CoNLLDataset class can be used \"\"\"\n",
    "\"\"\" Not elegant but works perfectly fine :)                 \"\"\"\n",
    "\n",
    "def make_dummy_y(test_corpus):\n",
    "    y_dummy_data = []\n",
    "    for sentence in test_corpus:\n",
    "        dummy = []\n",
    "        dummy.extend(len(sentence)*\"O\")\n",
    "        y_dummy_data.append(dummy)\n",
    "    return y_dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_parl_from_iob2(array):\n",
    "    temp_lst = []\n",
    "    for tag in array:\n",
    "        if tag == \"O\":\n",
    "            temp_lst.append(0)\n",
    "        else:\n",
    "            temp_lst.append(1)\n",
    "    return temp_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_labels_unlabled_data(unlabeled):\n",
    "    length = 0\n",
    "    gold_labels = []\n",
    "    for sentences in unlabeled:\n",
    "        label = []\n",
    "        length += len(sentences)\n",
    "        for token in sentences:\n",
    "            if token[0].isupper() == True: # Checks if token has captial letter\n",
    "                label.append(1)\n",
    "                \n",
    "            else:\n",
    "                label.append(0) # Adds 0 if token has lower \n",
    "        gold_labels.append(label)\n",
    "    \n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_vocab =     ['B-GPE_LOC', 'I-DRV', 'I-LOC', 'B-PER', 'I-PER', 'B-PROD', \n",
    "                'I-GPE_ORG', 'B-GPE_ORG', 'B-EVT', 'B-DRV', 'I-PROD', 'B-ORG', 'B-MISC',\n",
    "                'I-MISC', 'I-GPE_LOC', 'B-LOC', 'I-ORG', 'I-EVT', 'O', '@UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting no_bokmaal-ud-test to list of dictionaries\n",
      "     1939 elements converted..\n",
      "Converting no_nynorsk-ud-test to list of dictionaries\n",
      "     1511 elements converted..\n",
      "Combining test set..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Norne Data loading stuff\"\"\"\n",
    "\n",
    "path = \"all_conllu/{0}.conllu\"\n",
    "file_list = [\"no_bokmaal-ud-test\", \"no_nynorsk-ud-test\"]\n",
    "\n",
    "test_split_no = convert_to_list_dict(path, file_list[0])\n",
    "test_split_ny = convert_to_list_dict(path, file_list[1])\n",
    "\n",
    "print(\"Combining test set..\")\n",
    "test_split = test_split_no + test_split_ny\n",
    "print(\"Success!\")\n",
    "\n",
    "x_test_tokens = [x[\"tokens\"] for x in test_split]\n",
    "y_test_labels = [y[\"ner_tags\"] for y in test_split]\n",
    "test_dataset = CoNLLDataset(x_test_tokens, y_test_labels, ner_vocab)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset, batch_size=1, shuffle=False, collate_fn=partial(collate_fn, gpu=gpu))\n",
    "\n",
    "\"\"\" Gold labels for NorNE test_dataset\"\"\"\n",
    "gold_labels = []\n",
    "for sentence_labels in test_dataset.ner_labels:\n",
    "    for label in sentence_labels:\n",
    "        gold_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parliamentary corpus data loading stuff\"\"\"\n",
    "\n",
    "rootdir=r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\parl_corpus_full\"\n",
    "corpora_normal_cap, corpora_lower = load_parl_corpus(rootdir, lower=True)\n",
    "gold_corp = parl_sentences_only(corpora_normal_cap)\n",
    "test_parl = parl_sentences_only(corpora_lower)\n",
    "\n",
    "_gold_labels_parl = gold_labels_unlabled_data(gold_corp)\n",
    "\n",
    "dummy_y_parl = make_dummy_y(test_parl)\n",
    "parl_lower_corpus = CoNLLDataset(test_parl, dummy_y_parl, ner_vocab)\n",
    "\n",
    "parl_loader = DataLoader(\n",
    "        parl_lower_corpus, batch_size=1, shuffle=False, collate_fn=partial(collate_fn, gpu=gpu))\n",
    "\n",
    "gold_labels_parl = [item for sublist  in _gold_labels_parl for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ltgoslo/norbert2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:37<00:00, 92.05it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:17<00:00, 94.84it/s]\n",
      "Some weights of the model checkpoint at ltgoslo/norbert2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.27it/s]\n",
      "100%|██████████| 58591/58591 [10:15<00:00, 95.14it/s] \n",
      "Some weights of the model checkpoint at ltgoslo/norbert2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.88it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:16<00:00, 94.97it/s] \n",
      "Some weights of the model checkpoint at ltgoslo/norbert2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.96it/s]\n",
      "100%|██████████| 58591/58591 [10:17<00:00, 94.82it/s] \n",
      "Some weights of the model checkpoint at ltgoslo/norbert2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:35<00:00, 96.21it/s]\n",
      "100%|██████████| 58591/58591 [10:10<00:00, 95.96it/s] \n",
      "Some weights of the model checkpoint at NbAiLab/nb-bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.27it/s]\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.41it/s] \n",
      "Some weights of the model checkpoint at NbAiLab/nb-bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.87it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:21<00:00, 94.31it/s] \n",
      "Some weights of the model checkpoint at NbAiLab/nb-bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.16it/s]\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.50it/s] \n",
      "Some weights of the model checkpoint at NbAiLab/nb-bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.80it/s]\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.35it/s] \n",
      "Some weights of the model checkpoint at NbAiLab/nb-bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.72it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:21<00:00, 94.27it/s] \n",
      "Some weights of the model checkpoint at saattrupdan/nbailab-base-ner-scandi were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at saattrupdan/nbailab-base-ner-scandi and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.13it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.38it/s] \n",
      "Some weights of the model checkpoint at saattrupdan/nbailab-base-ner-scandi were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at saattrupdan/nbailab-base-ner-scandi and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.77it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:22<00:00, 94.19it/s] \n",
      "Some weights of the model checkpoint at saattrupdan/nbailab-base-ner-scandi were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at saattrupdan/nbailab-base-ner-scandi and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 94.96it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.43it/s] \n",
      "Some weights of the model checkpoint at saattrupdan/nbailab-base-ner-scandi were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at saattrupdan/nbailab-base-ner-scandi and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.07it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:22<00:00, 94.16it/s] \n",
      "Some weights of the model checkpoint at saattrupdan/nbailab-base-ner-scandi were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at saattrupdan/nbailab-base-ner-scandi and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3450/3450 [00:36<00:00, 95.20it/s]\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 58591/58591 [10:20<00:00, 94.37it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# relative paths only works half of the time on my windows machine :(\n",
    "model_types = {\n",
    "    \"ltgoslo/norbert2\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\NORBERT2\\trained models\",\n",
    "    \"NbAiLab/nb-bert-base\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\NB-BERT\\trained models nb-bert\",\n",
    "    \"saattrupdan/nbailab-base-ner-scandi\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\scandi-bert\\trained models scandi_bert\"\n",
    "}\n",
    "\n",
    "for model_type, trained_models_path in model_types.items():\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_type, do_basic_tokenize=False)\n",
    "    for subdir, dirs, files in os.walk(trained_models_path):\n",
    "        for file in files:\n",
    "            if \".json\" not in file:\n",
    "                bert_model = Bert(ner_vocab, model_type, freeze=False).to(device)\n",
    "                bert_train_path = os.path.join(subdir, file)\n",
    "                bert_model.load_state_dict(torch.load(bert_train_path))\n",
    "                \n",
    "                # Writing stuff for norne data\n",
    "\n",
    "                y_pred_norne = predict_test(test_loader, ner_vocab, tokenizer, bert_model)\n",
    "                norne_cr = classification_report(gold_labels, y_pred_norne, labels = ner_vocab[:-2], digits=5, output_dict=True)\n",
    "                norne_cf_matrix = confusion_matrix(gold_labels, y_pred_norne, labels = ner_vocab[:-2])\n",
    "\n",
    "                norne_cr_df = pd.DataFrame(norne_cr).transpose()\n",
    "                norne_cf_df = pd.DataFrame(norne_cf_matrix)\n",
    "\n",
    "                norne_cf_df.columns = ner_vocab[:-2]\n",
    "                norne_cf_df.index = ner_vocab[:-2]\n",
    "\n",
    "                model_type_name = model_type.rsplit('/',1)[1]\n",
    "                file_name_cr = f\"norne_CR_{model_type_name}.csv\" \n",
    "                file_name_cf = f\"norne_CF_MATRIX_{model_type_name}.csv\"\n",
    "\n",
    "                current_directory = os.getcwd()\n",
    "                final_directory = os.path.join(current_directory, rf\"{model_type_name}\")\n",
    "                if not os.path.exists(final_directory):\n",
    "                    os.makedirs(final_directory)\n",
    "\n",
    "\n",
    "                with open(f\"{final_directory}\\{file_name_cr}\", \"a\") as f:\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(f\"NorNE_{file_name_cr[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "                    f.write(\"\\n\")\n",
    "                with open(f\"{final_directory}\\{file_name_cf}\", \"a\") as f:\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(f\"NorNE_{file_name_cf[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "                norne_cr_df.to_csv(f\"{final_directory}\\{file_name_cr}\", mode=\"a\")\n",
    "                norne_cf_df.to_csv(f\"{final_directory}\\{file_name_cf}\", mode=\"a\")\n",
    "\n",
    "\n",
    "                # Parl test \n",
    "                y_pred_parl = predict_test(parl_loader, ner_vocab, tokenizer, bert_model)\n",
    "                y_pred_parl_binary = binary_parl_from_iob2(y_pred_parl)\n",
    "\n",
    "                parl_cr = classification_report(gold_labels_parl, y_pred_parl_binary, digits=5, output_dict=True)\n",
    "                parl_cf_matrix = confusion_matrix(gold_labels_parl, y_pred_parl_binary)\n",
    "\n",
    "                parl_cr_df = pd.DataFrame(parl_cr).transpose()\n",
    "                parl_cf_df = pd.DataFrame(parl_cf_matrix)\n",
    "\n",
    "                parl_cf_df.columns = [0, 1]\n",
    "                parl_cf_df.index = [0, 1]\n",
    "\n",
    "                model_type_name = model_type.rsplit('/',1)[1]\n",
    "                file_name_cr = f\"parl_CR_{model_type_name}.csv\" \n",
    "                file_name_cf = f\"parl_CF_MATRIX_{model_type_name}.csv\"\n",
    "\n",
    "                current_directory = os.getcwd()\n",
    "                final_directory = os.path.join(current_directory, rf\"{model_type_name}\")\n",
    "                if not os.path.exists(final_directory):\n",
    "                    os.makedirs(final_directory)\n",
    "\n",
    "\n",
    "                with open(f\"{final_directory}\\{file_name_cr}\", \"a\") as f:\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(f\"parl_{file_name_cr[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "                    f.write(\"\\n\")\n",
    "                with open(f\"{final_directory}\\{file_name_cf}\", \"a\") as f:\n",
    "                    f.write(\"\\n\")\n",
    "                    f.write(f\"parl_{file_name_cf[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "                parl_cr_df.to_csv(f\"{final_directory}\\{file_name_cr}\", mode=\"a\")\n",
    "                parl_cf_df.to_csv(f\"{final_directory}\\{file_name_cf}\", mode=\"a\")\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# rootdir=r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\parl_corpus_full\\20170215\"\n",
    "\n",
    "# path_list_parl = []\n",
    "\n",
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     for file in files:\n",
    "#         if \"normalized_token_data.json\" in file:\n",
    "#             path = (os.path.join(subdir, file))\n",
    "#             path_list_parl.append(path)\n",
    "\n",
    "\n",
    "# # relative paths only works half of the time on my windows machine :(\n",
    "# model_types = {\n",
    "#     \"ltgoslo/norbert2\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\NORBERT2\\trained models\",\n",
    "#     \"NbAiLab/nb-bert-base\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\NB-BERT\\trained models nb-bert\",\n",
    "#     \"saattrupdan/nbailab-base-ner-scandi\": r\"C:\\Users\\Aarne\\Desktop\\Ferdig_code_folder\\BERT models\\scandi-bert\\trained models scandi_bert\"\n",
    "# }\n",
    "\n",
    "\n",
    "# for model_type, trained_models_path in model_types.items():\n",
    "#     TP = 0\n",
    "#     FP = 0\n",
    "#     FN = 0\n",
    "#     TN = 0\n",
    "#     tokenizer = BertTokenizer.from_pretrained(model_type, do_basic_tokenize=False)\n",
    "#     for subdir, dirs, files in os.walk(trained_models_path):\n",
    "#         for file in files:\n",
    "#             if \".json\" not in file:\n",
    "#                 for path in path_list_parl:\n",
    "#                     bert_model = Bert(ner_vocab, model_type, freeze=False).to(device)\n",
    "#                     bert_train_path = os.path.join(subdir, file)\n",
    "#                     bert_model.load_state_dict(torch.load(bert_train_path))\n",
    "                \n",
    "#                     #LOADING CORPUS\n",
    "\n",
    "#                     cn = ParlamentaryCorpus(path)\n",
    "#                     cl = ParlamentaryCorpus(path)\n",
    "\n",
    "#                     _gold_corp = cn.load_data(lower=False)\n",
    "#                     _test_parl = cl.load_data(lower=True)\n",
    "\n",
    "#                     gold_corp = list(_gold_corp.values())\n",
    "#                     test_parl = list(_test_parl.values())\n",
    "\n",
    "#                     gold_corp = gold_corp[1170:1171]\n",
    "#                     test_parl = test_parl[1170:1171]\n",
    "\n",
    "\n",
    "                    \n",
    "#                     gold_corp = gold_corp[1170:]\n",
    "#                     test_parl = test_parl[1170:]\n",
    "                    \n",
    "#                     length = 0\n",
    "#                     gold_labels = []\n",
    "#                     for sentences in gold_corp:\n",
    "#                         annotation = []\n",
    "#                         length += len(sentences)\n",
    "#                         for token in sentences:\n",
    "#                             if token[0].isupper() == True: # Checks if token has captial letter\n",
    "#                                 annotation.append(1)\n",
    "                                \n",
    "#                             else:\n",
    "#                                 annotation.append(0) # Adds 0 if token has lower \n",
    "#                         gold_labels.append(annotation)\n",
    "\n",
    "\n",
    "#                     dummy_y_parl = make_dummy_y(test_parl)\n",
    "#                     parl_lower_corpus = CoNLLDataset(test_parl, dummy_y_parl, ner_vocab)\n",
    "\n",
    "#                     parl_loader = DataLoader(\n",
    "#                             parl_lower_corpus, batch_size=1, shuffle=False, collate_fn=partial(collate_fn, gpu=gpu))\n",
    "\n",
    "#                     gold_labels_parl = [item for sublist  in gold_labels for item in sublist]\n",
    "\n",
    "\n",
    "#                     # Parl test \n",
    "#                     y_pred_parl = predict_test(parl_loader, ner_vocab, tokenizer, bert_model)\n",
    "#                     y_pred_parl_binary = binary_parl_from_iob2(y_pred_parl)\n",
    "\n",
    "#                     parl_cr = classification_report(gold_labels_parl, y_pred_parl_binary, digits=5, output_dict=True)\n",
    "#                     parl_cf_matrix = confusion_matrix(gold_labels_parl, y_pred_parl_binary)\n",
    "                    \n",
    "#                     TP += parl_cf_matrix[0][0]\n",
    "#                     FP += parl_cf_matrix[0][1]\n",
    "#                     FN += parl_cf_matrix[1][0]\n",
    "#                     TN += parl_cf_matrix[1][1]\n",
    "\n",
    "#         confusion_matrix_dictionary = {\n",
    "#             \"TP\": TP,\n",
    "#             \"FP\": FP,\n",
    "#             \"FN\": FN,\n",
    "#             \"TN\": TN\n",
    "#         }\n",
    "\n",
    "#                     # parl_cr_df = pd.DataFrame(parl_cr).transpose()\n",
    "#                     # parl_cf_df = pd.DataFrame(parl_cf_matrix)\n",
    "\n",
    "#                     # parl_cf_df.columns = [0, 1]\n",
    "#                     # parl_cf_df.index = [0, 1]\n",
    "\n",
    "#                     # model_type_name = model_type.rsplit('/',1)[1]\n",
    "#                     # file_name_cr = f\"parl_CR_{model_type_name}.csv\" \n",
    "#                     # file_name_cf = f\"parl_CF_MATRIX_{model_type_name}.csv\"\n",
    "\n",
    "#                     # current_directory = os.getcwd()\n",
    "#                     # final_directory = os.path.join(current_directory, rf\"{model_type_name}\")\n",
    "#                     # if not os.path.exists(final_directory):\n",
    "#                     #     os.makedirs(final_directory)\n",
    "\n",
    "\n",
    "#                     # with open(f\"{final_directory}\\{file_name_cr}\", \"a\") as f:\n",
    "#                     #     f.write(\"\\n\")\n",
    "#                     #     f.write(f\"parl_{file_name_cr[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "#                     #     f.write(\"\\n\")\n",
    "#                     # with open(f\"{final_directory}\\{file_name_cf}\", \"a\") as f:\n",
    "#                     #     f.write(\"\\n\")\n",
    "#                     #     f.write(f\"parl_{file_name_cf[3:-4]}_seed_{bert_train_path.rsplit('_')[-1]}\")\n",
    "#                     #     f.write(\"\\n\")\n",
    "\n",
    "#                     # parl_cr_df.to_csv(f\"{final_directory}\\{file_name_cr}\", mode=\"a\")\n",
    "#                     # parl_cf_df.to_csv(f\"{final_directory}\\{file_name_cf}\", mode=\"a\")\n",
    "\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e5f1d1d80de0e037045f44f922af48a35ae55538dc259ba83b72568cdb122e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
