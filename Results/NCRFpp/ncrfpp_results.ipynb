{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import classification_report as cr\n",
    "from seqeval.metrics import performance_measure\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import performance_measure\n",
    "import conllu\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,f1_score, precision_score, recall_score, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\Aarne\\OneDrive - University of Bergen\\Dokumenter\\GitHub\\MA_Peter-R-ysland-Aarnes\\Results\\NCRFpp\\prediction_norne_ncrf.txt\", \"r\") as f:\n",
    "    preds_norne = f.readlines()\n",
    "with open(r\"C:\\Users\\Aarne\\OneDrive - University of Bergen\\Dokumenter\\GitHub\\MA_Peter-R-ysland-Aarnes\\Results\\NCRFpp\\prediction_parl_ncrf.txt\", \"r\") as f:\n",
    "    preds_parl = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_norne = [re.sub('\\n', '', line) for line in preds_norne]\n",
    "preds_parl = [re.sub('\\n', '', line) for line in preds_parl]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavily insipired from:\n",
    "# https://github.com/ltgoslo/NorBERT/blob/main/benchmarking/experiments/dataset.py\n",
    "\n",
    "class CoNLLDataset(Dataset):\n",
    "    def __init__(self, x_tokens, y_labels, ner_vocab=None):\n",
    "        self.tokens = [[x for x in entry] for entry in x_tokens]\n",
    "        self.ner_labels = [[y for y in entry] for entry in y_labels]\n",
    "\n",
    "        # hard coded ner_vocab to avoid random shuffled instanciation of ordering of ner_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.ner_indexer = {i: n for n, i in enumerate(self.ner_vocab)}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        tokens = self.tokens[index]\n",
    "        ner_labels = self.ner_labels[index]\n",
    "\n",
    "        x = tokens\n",
    "        y = torch.LongTensor([self.ner_indexer[i] if i in self.ner_vocab\n",
    "                              else self.ner_indexer['@UNK'] for i in ner_labels])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class ParlamentaryCorpus():\n",
    "\n",
    "    def __init__(self, path): # Takes input normalized_token_file\n",
    "        self.path = path\n",
    "        self.sentence_dict = {}\n",
    "\n",
    "    def load_data(self, lower=False):\n",
    "        sentence_dict = self.sentence_dict\n",
    "        with open(self.path) as infile:\n",
    "            with open(self.path, encoding=\"UTF-8\") as infile:\n",
    "                json_input = json.load(infile)\n",
    "\n",
    "        if lower == False:\n",
    "            for chaos in json_input[\"sentences\"]:\n",
    "                token_list = []\n",
    "                for token in chaos[\"tokens\"]:\n",
    "                    if token[\"special_status\"] != None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if \" \" in token[\"token_text\"]:\n",
    "                            token_list.extend(token[\"token_text\"].split())\n",
    "                        else:\n",
    "                            token_list.append(token[\"token_text\"])\n",
    "                    sentence_dict[chaos[\"sentence_id\"]] = token_list\n",
    "        else:\n",
    "            for chaos in json_input[\"sentences\"]:\n",
    "                token_list = []\n",
    "                for token in chaos[\"tokens\"]:\n",
    "                    if token[\"special_status\"] != None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if \" \" in token[\"token_text\"]:\n",
    "                            token_list.extend(token[\"token_text\"].lower().split())\n",
    "                        else:\n",
    "                            token_list.append(token[\"token_text\"].lower())\n",
    "                    sentence_dict[chaos[\"sentence_id\"]] = token_list\n",
    "                    \n",
    "        return sentence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conllu stuff\n",
    "def filter_tags(x):\n",
    "    return x        \n",
    "\n",
    "def convert_to_list_dict(path, file):\n",
    "    path = path.format(file)\n",
    "    with open(path, encoding=\"UTF-8\") as infile:\n",
    "        lst = []\n",
    "        tokens = list(conllu.parse_incr(infile))\n",
    "        for sent in tokens:\n",
    "                dic = {\n",
    "                \"idx\": sent.metadata[\"sent_id\"],\n",
    "                \"text\": sent.metadata[\"text\"].lower(),\n",
    "                \"tokens\": [token[\"form\"].lower() for token in sent],\n",
    "                \"lemmas\": [token[\"lemma\"] for token in sent],\n",
    "                \"pos_tags\": [token[\"upos\"] for token in sent],\n",
    "                \"ner_tags\": [filter_tags(token[\"misc\"].get(\"name\", \"O\")) for token in sent],\n",
    "            }\n",
    "                lst.append(dic) \n",
    "        print(\"Converting {} to list of dictionaries\\n     {} elements converted..\".format(file, len(lst)))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting no_bokmaal-ud-test to list of dictionaries\n",
      "     1939 elements converted..\n",
      "Converting no_nynorsk-ud-test to list of dictionaries\n",
      "     1511 elements converted..\n"
     ]
    }
   ],
   "source": [
    "path = \"all_conllu/{0}.conllu\"\n",
    "file_list = [\"no_bokmaal-ud-dev\", \"no_bokmaal-ud-test\", \"no_bokmaal-ud-train\", \"no_nynorsk-ud-dev\", \"no_nynorsk-ud-test\", \"no_nynorsk-ud-train\"]\n",
    "test_split_no = convert_to_list_dict(path, file_list[1])\n",
    "test_split_ny = convert_to_list_dict(path, file_list[4])\n",
    "test_split = test_split_no + test_split_ny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_vocab =     ['B-GPE_LOC', 'I-DRV', 'I-LOC', 'B-PER', 'I-PER', 'B-PROD', \n",
    "                'I-GPE_ORG', 'B-GPE_ORG', 'B-EVT', 'B-DRV', 'I-PROD', 'B-ORG', 'B-MISC',\n",
    "                'I-MISC', 'I-GPE_LOC', 'B-LOC', 'I-ORG', 'I-EVT', 'O', '@UNK']\n",
    "\n",
    "x_test_tokens = [x[\"tokens\"] for x in test_split]\n",
    "y_test_labels = [y[\"ner_tags\"] for y in test_split]\n",
    "test_dataset = CoNLLDataset(x_test_tokens, y_test_labels, ner_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels = []\n",
    "for sentence_labels in test_dataset.ner_labels:\n",
    "    for label in sentence_labels:\n",
    "        gold_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making list of lists preds, same len as NorNE gold labels\"\"\"\n",
    "\"\"\" test_dataset_ner_labels should be test_dataset.ner_labels \"\"\"\n",
    "\n",
    "def split_list_preds(preds, test_dataset_ner_labels):\n",
    "    split_list_preds = []\n",
    "    start = 0\n",
    "\n",
    "    for sublist in test_dataset_ner_labels:\n",
    "        end = start + len(sublist)\n",
    "        split_list_preds.append(preds[start:end])\n",
    "        start = end\n",
    "    return split_list_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_binary(set):\n",
    "    binary_labels = []\n",
    "    for label in set:\n",
    "        if label == \"O\":\n",
    "            binary_labels.append(0)\n",
    "        else:\n",
    "            binary_labels.append(1)\n",
    "    return binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_labels_unlabled_data(unlabeled):\n",
    "    length = 0\n",
    "    gold_labels = []\n",
    "    for sentences in unlabeled:\n",
    "        label = []\n",
    "        length += len(sentences)\n",
    "        for token in sentences:\n",
    "            if token[0].isupper() == True: # Checks if token has captial letter\n",
    "                label.append(1)\n",
    "                \n",
    "            else:\n",
    "                label.append(0) # Adds 0 if token has lower \n",
    "        gold_labels.append(label)\n",
    "    \n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parl_sentences_only(dictionary_corpus):\n",
    "    corp = []\n",
    "    for diction in dictionary_corpus:\n",
    "        corp += list(diction.values())\n",
    "    return corp\n",
    "\n",
    "def load_parl_corpus(rootdir_parl_corpus, lower=False):\n",
    "    corpora_normal_cap, corpora_lower, paths = [], [], []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(rootdir_parl_corpus):\n",
    "        for file in files:\n",
    "            if \"normalized_token_data.json\" in file:\n",
    "                path = (os.path.join(subdir, file))\n",
    "                paths.append(path)\n",
    "\n",
    "    for corpus, path in enumerate(paths):\n",
    "        corpus = ParlamentaryCorpus(path)\n",
    "        corpus = corpus.load_data()\n",
    "        corpora_normal_cap.append(corpus)\n",
    "        for k, v in corpus.items():\n",
    "            if v == []:\n",
    "                print(k)\n",
    "                print(path)\n",
    "\n",
    "    if lower==True:\n",
    "        for corpus, path in enumerate(paths):\n",
    "            corpus = ParlamentaryCorpus(path)\n",
    "            corpus = corpus.load_data(lower=True)\n",
    "            corpora_lower.append(corpus)\n",
    "\n",
    "\n",
    "    return corpora_normal_cap, corpora_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Reults section '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Reults section \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir=r\"C:\\Users\\Aarne\\OneDrive - University of Bergen\\Dokumenter\\GitHub\\MA_Peter-R-ysland-Aarnes\\parl_corpus_full\"\n",
    "corpora_normal_cap, corpora_lower = load_parl_corpus(rootdir, lower=True)\n",
    "gold_corp = parl_sentences_only(corpora_normal_cap)\n",
    "_gold_labels_parl = gold_labels_unlabled_data(gold_corp)\n",
    "gold_labels_parl = [item for sublist  in _gold_labels_parl for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "norne_preds_binary = transform_to_binary(preds_norne)\n",
    "parl_preds_binary = transform_to_binary(preds_parl)\n",
    "gold_binary = transform_to_binary(gold_labels)\n",
    "y_pred_parl_binary = transform_to_binary(preds_parl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_split_sentences = split_list_preds(preds_norne, test_dataset.ner_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Aarne\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFICATION REPORT\n",
    "norne_cr_df_all_labels = classification_report(gold_labels, preds_norne, labels = ner_vocab[:-2], digits=5, output_dict=True)\n",
    "norne_cr_IOB2 = cr(test_dataset.ner_labels, preds_split_sentences, mode='strict', scheme=IOB2, digits=4, output_dict=True)\n",
    "norne_cr_binary = classification_report(gold_binary, norne_preds_binary, digits=5, output_dict=True)\n",
    "\n",
    "norne_cr_df_all_labels = pd.DataFrame(norne_cr_df_all_labels).transpose()\n",
    "norne_cr_df_IOB2 = pd.DataFrame(norne_cr_IOB2).transpose()\n",
    "norne_cr_df_binary = pd.DataFrame(norne_cr_binary).transpose()\n",
    "\n",
    "\n",
    "## CONFUSION MATRIX\n",
    "norne_cf_matrix_no_O = confusion_matrix(gold_labels, preds_norne, labels = ner_vocab[:-2])\n",
    "norne_cf_matrix_O = confusion_matrix(gold_labels, preds_norne, labels = ner_vocab[:-1])\n",
    "norne_cr_matrix_binary = confusion_matrix(gold_binary, norne_preds_binary)\n",
    "\n",
    "norne_cf_df_no_O = pd.DataFrame(norne_cf_matrix_no_O)\n",
    "norne_cf_df_O = pd.DataFrame(norne_cf_matrix_O)\n",
    "norne_cf_df_binary = pd.DataFrame(norne_cr_matrix_binary)\n",
    "\n",
    "norne_cf_df_no_O.columns = ner_vocab[:-2]\n",
    "norne_cf_df_no_O.index = ner_vocab[:-2]\n",
    "norne_cf_df_O.columns = ner_vocab[:-1]\n",
    "norne_cf_df_O.index = ner_vocab[:-1]\n",
    "\n",
    "\n",
    "# class report\n",
    "norne_cr_df_all_labels.to_csv(\"norne_cr_df_all_labels\", mode=\"w\")\n",
    "norne_cr_df_IOB2.to_csv(\"norne_cr_df_IOB2\", mode=\"w\")\n",
    "norne_cr_df_binary.to_csv(\"norne_cr_df_binary\", mode=\"w\")\n",
    "\n",
    "#confusion matrix\n",
    "norne_cf_df_no_O.to_csv(\"norne_cf_df_no_O\", mode=\"w\")\n",
    "norne_cf_df_O.to_csv(\"norne_cf_df_O\", mode=\"w\")\n",
    "norne_cf_df_binary.to_csv(\"norne_cf_df_binary\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parl_cr = classification_report(gold_labels_parl, y_pred_parl_binary, digits=5, output_dict=True)\n",
    "parl_cf_matrix = confusion_matrix(gold_labels_parl, y_pred_parl_binary)\n",
    "\n",
    "parl_cr_df = pd.DataFrame(parl_cr).transpose()\n",
    "parl_cf_df = pd.DataFrame(parl_cf_matrix)\n",
    "\n",
    "parl_cf_df.columns = [0, 1]\n",
    "parl_cf_df.index = [0, 1]\n",
    "\n",
    "parl_cr_df = pd.DataFrame(parl_cr).transpose()\n",
    "parl_cf_df = pd.DataFrame(parl_cf_matrix)\n",
    "\n",
    "parl_cf_df.columns = [0, 1]\n",
    "parl_cf_df.index = [0, 1]\n",
    "\n",
    "parl_cr_df.to_csv(\"parl_classification_report_ncrf\", mode=\"w\")\n",
    "parl_cf_df.to_csv(\"parl_matrix_ncrf\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e5f1d1d80de0e037045f44f922af48a35ae55538dc259ba83b72568cdb122e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
