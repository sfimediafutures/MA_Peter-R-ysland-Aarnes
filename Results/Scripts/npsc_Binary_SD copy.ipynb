{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_files(root_dir, binary=None, iob=None):\n",
    "    file_paths = {}\n",
    "    for dir_name, subdir_list, file_list in os.walk(root_dir):\n",
    "        for file_name in file_list:\n",
    "            if binary:\n",
    "                if 'parl_CR_binary' in file_name:\n",
    "                    file_path = os.path.join(dir_name, file_name)\n",
    "                    key = file_name.replace('parl_CR_binary', '')\n",
    "                    file_paths[key] = file_path\n",
    "            if iob:\n",
    "                if \"NSPC_SAMPLES_CR_all_labels_\" in file_name:\n",
    "                    file_path = os.path.join(dir_name, file_name)\n",
    "                    key = file_name.replace('NSPC_SAMPLES_CR_IOB2_', '')\n",
    "                    file_paths[key] = file_path\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = r'C:\\Users\\Aarne\\OneDrive - University of Bergen\\Dokumenter\\GitHub\\MA_Peter-R-ysland-Aarnes\\Results'\n",
    "files = find_files(root_directory, binary=True)\n",
    "files_iob = find_files(root_directory, iob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_iob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_bert-base-multilingual-cased.csv': 'C:\\\\Users\\\\Aarne\\\\OneDrive - University of Bergen\\\\Dokumenter\\\\GitHub\\\\MA_Peter-R-ysland-Aarnes\\\\Results\\\\bert-base-multilingual-cased\\\\parl_CR_binary_bert-base-multilingual-cased.csv',\n",
       " '_nb-bert-base.csv': 'C:\\\\Users\\\\Aarne\\\\OneDrive - University of Bergen\\\\Dokumenter\\\\GitHub\\\\MA_Peter-R-ysland-Aarnes\\\\Results\\\\nb-bert-base\\\\parl_CR_binary_nb-bert-base.csv',\n",
       " '_nbailab-base-ner-scandi.csv': 'C:\\\\Users\\\\Aarne\\\\OneDrive - University of Bergen\\\\Dokumenter\\\\GitHub\\\\MA_Peter-R-ysland-Aarnes\\\\Results\\\\nbailab-base-ner-scandi\\\\parl_CR_binary_nbailab-base-ner-scandi.csv',\n",
       " '_norbert.csv': 'C:\\\\Users\\\\Aarne\\\\OneDrive - University of Bergen\\\\Dokumenter\\\\GitHub\\\\MA_Peter-R-ysland-Aarnes\\\\Results\\\\norbert\\\\parl_CR_binary_norbert.csv',\n",
       " '_norbert2.csv': 'C:\\\\Users\\\\Aarne\\\\OneDrive - University of Bergen\\\\Dokumenter\\\\GitHub\\\\MA_Peter-R-ysland-Aarnes\\\\Results\\\\norbert2\\\\parl_CR_binary_norbert2.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rows(file_path, row_type, binary=None, IOB2=None): #row type \"macro_avg\" etc\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        r, p, f1, s = [],[],[], []\n",
    "        for row in reader:\n",
    "            d = {}\n",
    "            if len(row) > 0 and row[0] == row_type and binary:\n",
    "                r.append(float(row[1])*100)\n",
    "                p.append(float(row[2])*100)\n",
    "                f1.append(float(row[3])*100)\n",
    "            elif len(row) > 0 and row[0] == row_type and IOB2:\n",
    "                r.append(float(row[1])*100)\n",
    "                p.append(float(row[2])*100)\n",
    "                f1.append(float(row[3])*100)\n",
    "                s.append(int(float(row[4])))\n",
    "        d[f\"precision\"]=p\n",
    "        d[\"recall\"]=r\n",
    "        d[f\"f1\"]=f1\n",
    "        d[f\"support\"]=s\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sd_from_extracted_rows_keys(iob2_data, key):\n",
    "    texts = []\n",
    "    latex = []\n",
    "    model_name=key.split(\".\")[0]\n",
    "\n",
    "    print(model_name)\n",
    "    for key in iob2_data:\n",
    "        values = [float(x) for x in iob2_data[key]]\n",
    "        avg = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        text = (f\"{key}: Average = {avg:.2f}, Standard Deviation = {std:.2f}\")\n",
    "        latex_text = (f\"{avg:.2f} (\\pm{{{std:.2f}}})\")\n",
    "        texts.append(text)\n",
    "        latex.append(latex_text)\n",
    "    for i in texts:\n",
    "        print(i)\n",
    "    for t in latex:\n",
    "        if t!=latex[-1]:\n",
    "            print(f\"{t} & \", end=\"\")\n",
    "        else:\n",
    "            print(f\"{t} \\\\\\\\ [2pt]\")\n",
    "    print()\n",
    "\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, v in files_iob.items():\n",
    "    iob2_data = extract_rows(v, \"micro avg\", IOB2=True)\n",
    "    get_sd_from_extracted_rows_keys(iob2_data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, v in files_iob.items():\n",
    "    if key==\"nbailab-base-ner-scandi.csv\":\n",
    "        iob2_data = extract_rows(v, \"micro avg\", IOB2=True)\n",
    "        get_sd_from_extracted_rows_keys(iob2_data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['B-GPE_LOC', 'I-DRV', 'I-LOC', 'B-PER', 'I-PER', 'B-PROD', \n",
    "                'I-GPE_ORG', 'B-GPE_ORG', 'B-EVT', 'B-DRV', 'I-PROD', 'B-ORG', 'B-MISC',\n",
    "                'I-MISC', 'I-GPE_LOC', 'B-LOC', 'I-ORG', 'I-EVT']\n",
    "d = {}\n",
    "for name in lst:\n",
    "    for key, v in files_iob.items():\n",
    "        if key==\"NSPC_SAMPLES_CR_all_labels_nb-bert-base.csv\":\n",
    "            d[name]=extract_rows(v, name, IOB2=True)\n",
    "\n",
    "all_latex = []\n",
    "for k, v in d.items():\n",
    "    latex = get_sd_from_extracted_rows_keys(v, k)\n",
    "    all_latex.append(latex)\n",
    "\n",
    "for latex, name in zip(all_latex, lst):\n",
    "    for i1 in latex:\n",
    "        if i1==latex[0]:\n",
    "            print(f\"{name} & {i1} &\", end=\" \")\n",
    "        elif i1!=latex[-1] and i1!=[0]:\n",
    "            print(f\"{i1}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"& {i1[:-15]} \\\\\\\\ [2pt]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in files_iob.items():\n",
    "    model_name=k.split(\".\")[0]\n",
    "    iob2_data = extract_rows(v, \"micro avg\", IOB2=True)\n",
    "    print()\n",
    "    print(model_name)\n",
    "    for key in iob2_data:\n",
    "        values = [float(x) for x in iob2_data[key]]\n",
    "        avg = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        print(f\"{key}: Average = {avg:.2f}, Standard Deviation = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"(\\pm{0.00})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_bert-base-multilingual-cased\n",
      "precision    95.25 (\\pm{0.32})\n",
      "recall    92.91 (\\pm{0.58})\n",
      "f1    94.04 (\\pm{0.20})\n",
      "support    nan (\\pm{nan})\n",
      "\n",
      "_nb-bert-base\n",
      "precision    97.78 (\\pm{0.23})\n",
      "recall    92.76 (\\pm{0.39})\n",
      "f1    95.11 (\\pm{0.23})\n",
      "support    nan (\\pm{nan})\n",
      "\n",
      "_nbailab-base-ner-scandi\n",
      "precision    97.56 (\\pm{0.18})\n",
      "recall    93.43 (\\pm{0.48})\n",
      "f1    95.39 (\\pm{0.23})\n",
      "support    nan (\\pm{nan})\n",
      "\n",
      "_norbert\n",
      "precision    96.55 (\\pm{0.47})\n",
      "recall    93.19 (\\pm{0.97})\n",
      "f1    94.79 (\\pm{0.35})\n",
      "support    nan (\\pm{nan})\n",
      "\n",
      "_norbert2\n",
      "precision    97.10 (\\pm{0.22})\n",
      "recall    93.10 (\\pm{0.44})\n",
      "f1    95.00 (\\pm{0.19})\n",
      "support    nan (\\pm{nan})\n"
     ]
    }
   ],
   "source": [
    "for k, v in files.items():\n",
    "    model_name=k.split(\".\")[0]\n",
    "    data = extract_rows(v, row_type=\"macro avg\", binary=True)\n",
    "    print()\n",
    "    print(model_name)\n",
    "    for key in data:\n",
    "        values = [float(x) for x in data[key]]\n",
    "        avg = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        #print(f\"{key}: Average = {avg:.2f}, Standard Deviation = {std:.2f}\")\n",
    "        print(f\"{key}    {avg:.2f} (\\pm{{{std:.2f}}})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
