{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class ParlamentaryCorpus():\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def load_data(self, lower=False):\n",
    "        return_data = []\n",
    "        with open(self.path) as infile:\n",
    "            with open(self.path, encoding=\"UTF-8\") as infile:\n",
    "                data = json.load(infile)\n",
    "        for sentence in data[\"sentences\"]:\n",
    "            info = {}\n",
    "            if lower == True:\n",
    "                re_sentence = re.sub(\"<.*?>\", \"\", sentence[\"sentence_text\"].lower())\n",
    "                info[sentence[\"sentence_id\"]] = re_sentence\n",
    "            else:\n",
    "                re_sentence = re.sub(\"<.*?>\", \"\", sentence[\"sentence_text\"])\n",
    "                info[sentence[\"sentence_id\"]] = re_sentence\n",
    "            return_data.append(info)\n",
    "        return return_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_parl(corpus):\n",
    "    tokenized_corpus = []\n",
    "    for item in corpus:\n",
    "        for value in item.values():\n",
    "            tokenized_corpus.append((word_tokenize(value)))\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r\"C:\\Users\\Aarne\\Desktop\\z NPSC (norwegian parliamentary speech corpus) sample\\20170207\\20170207_sentence_data.json\"\n",
    "path2 = r\"C:\\Users\\Aarne\\Desktop\\z NPSC (norwegian parliamentary speech corpus) sample\\20170110\\20170110_sentence_data.json\"\n",
    "\n",
    "c1 = ParlamentaryCorpus(path1)\n",
    "c2 = ParlamentaryCorpus(path2)\n",
    "c1_gold = c1.load_data()\n",
    "c2_gold = c2.load_data()\n",
    "lowered_corpus1 = c1.load_data(lower=True)\n",
    "lowered_corpus2 = c2.load_data(lower=True)\n",
    "\n",
    "lowered_corpus = lowered_corpus1 + lowered_corpus2\n",
    "gold_corpus = c1_gold + c2_gold\n",
    "\n",
    "tokens_lower_corpus = tokenize_parl(lowered_corpus)\n",
    "token_gold_corpus = tokenize_parl(gold_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bmes_file_ncrfpp_parl(filename, lst):\n",
    "    with open(f\"{filename}.bmes\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        for sent in lst:\n",
    "            to_file = []\n",
    "            for token in sent:\n",
    "                token_tag = f\"{token} O\"\n",
    "                to_file.append(token_tag)\n",
    "            for line in to_file:\n",
    "                file.write(line)\n",
    "                file.write(\"\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_bmes_file_ncrfpp_parl(\"parl_corp_for_ncrfpp\", tokens_lower_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e5f1d1d80de0e037045f44f922af48a35ae55538dc259ba83b72568cdb122e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
